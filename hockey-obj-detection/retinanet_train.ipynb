{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def makedirs(path):\n",
    "    # Intended behavior: try to create the directory,\n",
    "    # pass if the directory exists already, fails otherwise.\n",
    "    # Meant for Python 2.7/3.n compatibility.\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise\n",
    "\n",
    "def get_session():\n",
    "    \"\"\" Construct a modified tf session.\n",
    "    \"\"\"\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurable Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # Paths\n",
    "    local_train_dir = os.path.join(os.path.dirname((os.getcwd())), 's3_training_data')\n",
    "    annotations=\"data/annotations.csv\" ## Path to CSV file containing annotation for training\n",
    "    classes=\"data/classmap.csv\"  ## Path to CSV containing class label mapping\n",
    "    val_annotations=\"data/val_annotations.csv\"\n",
    "    \n",
    "    # Network\n",
    "    backbone = \"resnet50\"\n",
    "    snapshot_path = 'snapshots'\n",
    "\n",
    "    # Hyperparameters\n",
    "    batch_size= 1 \n",
    "    epochs = 50 \n",
    "    steps = 10000 #steps per epoch\n",
    "    \n",
    "    # GPU\n",
    "    multi_gpu = 0 # Number of GPUs for parallel processing\n",
    "    gpu = None #ID of GPU as reported by nvidia-smi\n",
    "    \n",
    "    # Training variables\n",
    "    folder_names = [\"NYR-BOS_22m12s-22m30s\", \"PHI-PIT_6m-8m\"]\n",
    "    s3_bucket_name = \"bsivisiondata\"\n",
    "    update_csv_annotations = False\n",
    "    snapshot = None #Starting point for training\n",
    "    imagenet_weights = True\n",
    "    \n",
    "    \n",
    "    # keras-retinanet specific\n",
    "    evaluation = True\n",
    "    dataset_type = \"csv\"\n",
    "    snapshots = True #if true save snapshots\n",
    "    weights = None\n",
    "    random_transform = None\n",
    "    image_min_side = 800\n",
    "    image_max_side = 1333\n",
    "    tensorboard_dir = None\n",
    "    freeze_backbone = False\n",
    "    \n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0/150 files from DET-NSH_0h10m12s-0h10m17s/annotations/\n",
      "Downloaded 0/149 files from DET-NSH_0h10m12s-0h10m17s/frames/\n",
      "Downloaded 0/0 files from DET-NSH_0h10m12s-0h10m17s/\n",
      "Downloaded 0/597 files from DET-NSH_0h7m45s-0h8m5s/annotations/\n",
      "Downloaded 0/600 files from DET-NSH_0h7m45s-0h8m5s/frames/\n",
      "Downloaded 0/0 files from DET-NSH_0h7m45s-0h8m5s/\n",
      "Downloaded 0/184 files from NYR-BOS_22m12s-22m30s/annotations/\n",
      "Downloaded 0/285 files from NYR-BOS_22m12s-22m30s/frames/\n",
      "Downloaded 0/1 files from NYR-BOS_22m12s-22m30s/\n",
      "Downloaded 0/162 files from PHI-PIT_6m-8m/annotations/\n",
      "Downloaded 0/164 files from PHI-PIT_6m-8m/frames/\n",
      "Downloaded 0/3 files from PHI-PIT_6m-8m/\n",
      "Downloaded 0/4 files from \n",
      "S3 dataset downloaded\n"
     ]
    }
   ],
   "source": [
    "# Download S3 dataset\n",
    "from utils.file_manager import FileManager\n",
    "fm = FileManager('bsivisiondata')\n",
    "fm.download_dir('', local=args.local_train_dir)\n",
    "print(\"S3 dataset downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "CSV Ready\n"
     ]
    }
   ],
   "source": [
    "# Creates CSV file with photo annotations; filepath,x1,y1,x2,y2,class\n",
    "if args.update_csv_annotations or True:\n",
    "    from keras_retinanet.gen_csv_from_annotations import write_data_to_CSV\n",
    "    write_data_to_CSV(args.folder_names, args.s3_bucket_name, args.local_train_dir)\n",
    "print(\"CSV Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from keras_retinanet.bin.train import create_generators\n",
    "\n",
    "\n",
    "# create the generators\n",
    "train_generator, validation_generator = create_generators(args)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named keras_resnet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6caadbb02a38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# create object that stores backbone information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# make sure keras is the minimum required version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/campbellweaver/Documents/BSI/src/hockey-obj-detection/keras_retinanet/models/__init__.pyc\u001b[0m in \u001b[0;36mbackbone\u001b[0;34m(backbone_name)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'resnet'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNetBackbone\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'mobilenet'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmobilenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMobileNetBackbone\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/campbellweaver/Documents/BSI/src/hockey-obj-detection/keras_retinanet/models/resnet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_resnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_resnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named keras_resnet"
     ]
    }
   ],
   "source": [
    "from keras_retinanet.bin.train import create_models, check_keras_version\n",
    "from keras_retinanet import models\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "# create object that stores backbone information\n",
    "backbone = models.backbone(args.backbone)\n",
    "\n",
    "# make sure keras is the minimum required version\n",
    "check_keras_version()\n",
    "\n",
    "\n",
    "# optionally choose specific GPU\n",
    "if args.gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "set_session(get_session())\n",
    "\n",
    "# create the model\n",
    "if args.snapshot is not None:\n",
    "    model            = models.load_model(args.snapshot, backbone_name=args.backbone)\n",
    "    training_model   = model\n",
    "    prediction_model = retinanet_bbox(model=model)\n",
    "else:\n",
    "    weights = args.weights\n",
    "    # default to imagenet if nothing else is specified\n",
    "    if weights is None and args.imagenet_weights:\n",
    "        weights = backbone.download_imagenet()\n",
    "        model, training_model, prediction_model = create_models(\n",
    "            backbone_retinanet=backbone.retinanet,\n",
    "            num_classes=train_generator.num_classes(),\n",
    "            weights=weights,\n",
    "            multi_gpu=args.multi_gpu,\n",
    "            freeze_backbone=args.freeze_backbone\n",
    "        )\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "from keras_retinanet.bin.train import create_callbacks\n",
    "\n",
    "# this lets the generator compute backbone layer shapes using the actual backbone model\n",
    "if 'vgg' in args.backbone or 'densenet' in args.backbone:\n",
    "    compute_anchor_targets = functools.partial(anchor_targets_bbox, shapes_callback=make_shapes_callback(model))\n",
    "    train_generator.compute_anchor_targets = compute_anchor_targets\n",
    "    if validation_generator is not None:\n",
    "        validation_generator.compute_anchor_targets = compute_anchor_targets\n",
    "\n",
    "# create the callbacks\n",
    "callbacks = create_callbacks(\n",
    "    model,\n",
    "    training_model,\n",
    "    prediction_model,\n",
    "    validation_generator,\n",
    "    args,\n",
    ")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  260/10000 [..............................] - ETA: 2:31:27 - loss: 3.3184 - regression_loss: 2.4537 - classification_loss: 0.8647"
     ]
    }
   ],
   "source": [
    "training_model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=args.steps,\n",
    "    epochs=args.epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
